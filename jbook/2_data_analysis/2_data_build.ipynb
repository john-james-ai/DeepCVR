{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(section_22_data_build)=\n",
    "# Data Build\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# REMOVE-CELL\n",
    "home = \"/home/john/projects/DeepCVR/\"\n",
    "os.chdir(home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data pipeline constructed in this section will download, extract, merge, and load the data which wil be used to evaluate state-of-the-art conversion rate prediction algorithms throughout the rest of this series. Our dataset, the Ali-CCP: Alibaba Click and Conversion Prediction dataset may be obtained [Alibaba's Tianchi website](https://tianchi.aliyun.com/dataset/dataDetail?dataId=408) after registering with the website. Alternatively, the data may be downloaded from an Amazon S3 instance. For reproducibility purposes, all artifacts will be obtained from an Amazon S3 resource. \n",
    "\n",
    "Our data pipeline is summarized as follows:\n",
    "\n",
    "| # | Step                                              | Destination   |\n",
    "|---|---------------------------------------------------|---------------|\n",
    "| 1 | Download the data from an Amazon S3 Instance      | data/external |\n",
    "| 2 | Extract and secure the raw training and test sets | data/raw      |\n",
    "| 3 | Merge the core and common features datasets       | data/staged   |\n",
    "| 4 | Subsample the data for profiling and analysis     | data/sample   |\n",
    "\n",
    "```{tip} Reproducibility\n",
    ":class: dropdown\n",
    "To run this notebook on the cloud, click on the shuttle icon in the external links at the top right of the page. This will launch the notebook on a Google Colab instance.\n",
    "```\n",
    "```{tip} Viewing Source Code\n",
    ":class: dropdown \n",
    "Some of the source code is hidden by default. To view source code in this notebook, click on the icon 'Click to show' to the right.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants \n",
    "DIRECTORY_EXTERNAL = \"data/external\"\n",
    "DIRECTORY_RAW = 'data/raw'\n",
    "DIRECTORY_STAGED = 'data/staged'\n",
    "DIRECTORY_SAMPLE = 'data/sample'\n",
    "S3_BUCKET = 'deepcvr-data'\n",
    "FILENAME_CORE_TRAIN = \"sample_skeleton_train.csv\"\n",
    "FILENAME_COMMON_FEATURES_TRAIN = \"common_features_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Download\n",
    "import os\n",
    "import os\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '24'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '16'\n",
    "import boto3\n",
    "import logging\n",
    "import progressbar\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from deepcvr.utils.config import S3Config\n",
    "# Extract\n",
    "import os\n",
    "import logging\n",
    "import tarfile\n",
    "import tempfile\n",
    "# Inspection\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "import numpy as np\n",
    "import numexpr as ne\n",
    "# Logging objects\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data\n",
    "Downloading the data from our S3 instance will take approximately 15 minutes on a standard 40 Mbps internet line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s S3Downloader deepcvr/data/download.py\n",
    "class S3Downloader:\n",
    "    \"\"\"Download operator for Amazon S3 Resources\n",
    "\n",
    "    Args:\n",
    "        bucket (str): The name of the S3 bucket\n",
    "        destination (str): Director to which all resources are to be downloaded\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bucket: str, destination: str, force: bool = False) -> None:\n",
    "        self._bucket = bucket\n",
    "        self._destination = destination\n",
    "        self._force = force\n",
    "        config = S3Config()\n",
    "        self._s3 = boto3.client(\n",
    "            \"s3\", aws_access_key_id=config.key, aws_secret_access_key=config.secret\n",
    "        )\n",
    "        self._progressbar = None\n",
    "\n",
    "    def execute(self) -> None:\n",
    "\n",
    "        object_keys = self._list_bucket_contents()\n",
    "\n",
    "        for object_key in object_keys:\n",
    "            destination = os.path.join(self._destination, object_key)\n",
    "            if not os.path.exists(destination) or self._force:\n",
    "                self._download(object_key, destination)\n",
    "            else:\n",
    "                logger.info(\n",
    "                    \"Bucket resource {} already exists and was not downloaded.\".format(destination)\n",
    "                )\n",
    "\n",
    "    def _list_bucket_contents(self) -> list:\n",
    "        \"\"\"Returns a list of objects in the designated bucket\"\"\"\n",
    "        objects = []\n",
    "        s3 = boto3.resource(\"s3\")\n",
    "        bucket = s3.Bucket(self._bucket)\n",
    "        for object in bucket.objects.all():\n",
    "            objects.append(object.key)\n",
    "        return objects\n",
    "\n",
    "    def _download(self, object_key: str, destination: str) -> None:\n",
    "        \"\"\"Downloads object designated by the object ke if not exists or force is True\"\"\"\n",
    "\n",
    "        response = self._s3.head_object(Bucket=self._bucket, Key=object_key)\n",
    "        size = response[\"ContentLength\"]\n",
    "\n",
    "        self._progressbar = progressbar.progressbar.ProgressBar(maxval=size)\n",
    "        self._progressbar.start()\n",
    "\n",
    "        os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
    "        try:\n",
    "            self._s3.download_file(\n",
    "                self._bucket, object_key, destination, Callback=self._download_callback\n",
    "            )\n",
    "            logger.info(\"Download of {} Complete!\".format(object_key))\n",
    "        except NoCredentialsError:\n",
    "            msg = \"Credentials not available for {} bucket\".format(self._bucket)\n",
    "            raise NoCredentialsError(msg)\n",
    "\n",
    "    def _download_callback(self, size):\n",
    "        self._progressbar.update(self._progressbar.currval + size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Credentials found in config file: ~/.aws/config\n",
      "INFO:__main__:Bucket resource data/external/taobao_test.tar.gz already exists and was not downloaded.\n",
      "INFO:__main__:Bucket resource data/external/taobao_train.tar.gz already exists and was not downloaded.\n"
     ]
    }
   ],
   "source": [
    "downloader = S3Downloader(bucket=S3_BUCKET, destination=DIRECTORY_EXTERNAL)\n",
    "downloader.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Raw Data\n",
    "Here, we extract the compressed files into a raw data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# %load -s Extractor deepcvr/data/extract.py\n",
    "class Extractor:\n",
    "    \"\"\"Decompresses a gzip archive, stores the raw data\n",
    "\n",
    "    Args:\n",
    "        source (str): The filepath to the source file to be decompressed\n",
    "        destination (str): The destination directory into which data shall be stored.\n",
    "        filetype (str): The file extension for the uncompressed data\n",
    "        force (bool): Forces extraction even when files already exist.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, source: str, destination: str, force: bool = False) -> None:\n",
    "\n",
    "        self._source = source\n",
    "        self._destination = destination\n",
    "        self._force = force\n",
    "\n",
    "    def execute(self) -> None:\n",
    "        \"\"\"Extracts and stores the data, then pushes filepaths to xCom.\"\"\"\n",
    "        logger.debug(\"\\tSource: {}\\tDestination: {}\".format(self._source, self._destination))\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as tempdir:\n",
    "            # Recursively extract data and store in destination directory\n",
    "            self._extract(source=self._source, destination=tempdir)\n",
    "\n",
    "    def _extract(self, source: str, destination: str) -> None:\n",
    "        \"\"\"Extracts the data and returns the extracted filepaths\"\"\"\n",
    "\n",
    "        logger.debug(\"\\t\\tOpening {}\".format(source))\n",
    "        data = tarfile.open(source)\n",
    "\n",
    "        for member in data.getmembers():\n",
    "            if self._is_csvfile(filename=member.name):\n",
    "                if self._not_exists_or_force(member_name=member.name):\n",
    "                    logger.debug(\"\\t\\tExtracting {} to {}\".format(member.name, self._destination))\n",
    "                    data.extract(member, self._destination)  # Extract to destination\n",
    "                else:\n",
    "                    pass  # Do nothing if the csv file already exists and Force is False\n",
    "\n",
    "            else:\n",
    "                logger.debug(\"\\t\\tExtracting {} to {}\".format(member.name, destination))\n",
    "                data.extract(member, destination)  # Extract to tempdirectory\n",
    "\n",
    "    def _not_exists_or_force(self, member_name: str) -> bool:\n",
    "        \"\"\"Returns true if the file doesn't exist or force is True.\"\"\"\n",
    "        filepath = os.path.join(self._destination, member_name)\n",
    "        return not os.path.exists(filepath) or self._force\n",
    "\n",
    "    def _is_csvfile(self, filename: str) -> bool:\n",
    "        \"\"\"Returns True if filename is a csv file, returns False otherwise.\"\"\"\n",
    "        return \".csv\" in filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_skeleton_train.csv',\n",
       " 'sample_skeleton_test.csv',\n",
       " 'common_features_test.csv',\n",
       " 'common_features_train.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor = Extractor()\n",
    "filenames = extractor.execute(source=DIRECTORY_EXTERNAL, destination=DIRECTORY_RAW)\n",
    "os.listdir(DIRECTORY_RAW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Dataset Preprocessing\n",
    "Let's take a preliminary look at the core training dataset.\n",
    "### Core Raw Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bacff91692951881</td>\n",
       "      <td>9</td>\n",
       "      <td>210\u00029052218\u00031.0\u0001210\u00029064553\u00031.0\u0001210\u00029093445\u00031.0\u0001216\u00029154780\u00031.0\u0001301\u00029351665\u00031.0\u0001205\u00024186222\u00031.0\u0001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bacff91692951881</td>\n",
       "      <td>10</td>\n",
       "      <td>210\u00029109732\u00031.0\u0001210\u00029046284\u00031.0\u0001210\u00029099035\u00031.0\u0001210\u00029046540\u00031.0\u0001210\u00029104107\u00031.0\u0001216\u00029188757\u00031.0\u0001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>bacff91692951881</td>\n",
       "      <td>20</td>\n",
       "      <td>210\u00029089731\u00031.0\u0001210\u00029047560\u00031.0\u0001509\u00029511769\u00032.30259\u0001508\u00029354837\u00035.14166\u0001702\u00029867762\u00034.02535\u0001853\u0002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bacff91692951881</td>\n",
       "      <td>13</td>\n",
       "      <td>301\u00029351665\u00031.0\u0001210\u00029050364\u00031.0\u0001210\u00029083388\u00031.0\u0001210\u00029104229\u00031.0\u0001210\u00029035395\u00031.0\u0001508\u00029354448\u00032.39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bacff91692951881</td>\n",
       "      <td>9</td>\n",
       "      <td>205\u00024945663\u00031.0\u0001301\u00029351665\u00031.0\u0001216\u00029172179\u00031.0\u0001210\u00029028389\u00031.0\u0001210\u00029062272\u00031.0\u0001210\u00029030554\u00031.0\u0001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2                 3   4                                                                                                    5\n",
       "0                                                                                                                                 \n",
       "1  0  0  bacff91692951881   9  210\u00029052218\u00031.0\u0001210\u00029064553\u00031.0\u0001210\u00029093445\u00031.0\u0001216\u00029154780\u00031.0\u0001301\u00029351665\u00031.0\u0001205\u00024186222\u00031.0\u0001...\n",
       "2  0  0  bacff91692951881  10  210\u00029109732\u00031.0\u0001210\u00029046284\u00031.0\u0001210\u00029099035\u00031.0\u0001210\u00029046540\u00031.0\u0001210\u00029104107\u00031.0\u0001216\u00029188757\u00031.0\u0001...\n",
       "3  1  0  bacff91692951881  20  210\u00029089731\u00031.0\u0001210\u00029047560\u00031.0\u0001509\u00029511769\u00032.30259\u0001508\u00029354837\u00035.14166\u0001702\u00029867762\u00034.02535\u0001853\u0002...\n",
       "4  0  0  bacff91692951881  13  301\u00029351665\u00031.0\u0001210\u00029050364\u00031.0\u0001210\u00029083388\u00031.0\u0001210\u00029104229\u00031.0\u0001210\u00029035395\u00031.0\u0001508\u00029354448\u00032.39...\n",
       "5  0  0  bacff91692951881   9  205\u00024945663\u00031.0\u0001301\u00029351665\u00031.0\u0001216\u00029172179\u00031.0\u0001210\u00029028389\u00031.0\u0001210\u00029062272\u00031.0\u0001210\u00029030554\u00031.0\u0001..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_core_filepath = os.path.join(DIRECTORY_RAW,FILENAME_CORE_TRAIN)\n",
    "df = pd.read_csv(raw_train_core_filepath, header=None, index_col=0, nrows=100)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have: \n",
    "\n",
    "| Column | Field                                  |\n",
    "|--------|----------------------------------------|\n",
    "| 0      | Sample-id                              |\n",
    "| 1      | Click Label                            |\n",
    "| 2      | Conversion Label                       |\n",
    "| 3      | Common Features Foreign Key            |\n",
    "| 4      | Number of features in the feature list |\n",
    "| 5      | Feature List                           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84dceed2e3a667f8</th>\n",
       "      <td>343</td>\n",
       "      <td>101\u000231319\u00031.0\u0001125\u00023438774\u00031.0\u0001126\u00023438779\u00031.0\u0001127\u00023438782\u00031.0\u0001128\u00023864885\u00031.0\u0001129\u00023864888\u00031.0\u000115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000350f0c2121e7</th>\n",
       "      <td>811</td>\n",
       "      <td>127_14\u00023716224\u00031.94591\u0001127_14\u00023514627\u00030.69315\u0001127_14\u00023772871\u00030.69315\u0001127_14\u00023543283\u00031.60944\u0001127_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000091a89d1867ab</th>\n",
       "      <td>7</td>\n",
       "      <td>125\u00023438773\u00031.0\u0001124\u00023438769\u00031.0\u0001122\u00023438761\u00031.0\u0001121\u00023438658\u00031.0\u0001129\u00023864889\u00031.0\u0001128\u00023864885\u00031.0\u0001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001a4114b0ae8bf</th>\n",
       "      <td>231</td>\n",
       "      <td>150_14\u00023916684\u00032.3979\u0001150_14\u00023940798\u00031.07056\u0001150_14\u00023892368\u00031.6259\u0001150_14\u00023914634\u00030.55962\u0001150_14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001def19d7cb335</th>\n",
       "      <td>964</td>\n",
       "      <td>150_14\u00023909150\u00030.84715\u0001150_14\u00023933013\u00034.44265\u0001150_14\u00023934083\u00033.3322\u0001150_14\u00023874258\u00034.09988\u0001150_1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    1                                                                                                    2\n",
       "0                                                                                                                         \n",
       "84dceed2e3a667f8  343  101\u000231319\u00031.0\u0001125\u00023438774\u00031.0\u0001126\u00023438779\u00031.0\u0001127\u00023438782\u00031.0\u0001128\u00023864885\u00031.0\u0001129\u00023864888\u00031.0\u000115...\n",
       "0000350f0c2121e7  811  127_14\u00023716224\u00031.94591\u0001127_14\u00023514627\u00030.69315\u0001127_14\u00023772871\u00030.69315\u0001127_14\u00023543283\u00031.60944\u0001127_...\n",
       "000091a89d1867ab    7  125\u00023438773\u00031.0\u0001124\u00023438769\u00031.0\u0001122\u00023438761\u00031.0\u0001121\u00023438658\u00031.0\u0001129\u00023864889\u00031.0\u0001128\u00023864885\u00031.0\u0001...\n",
       "0001a4114b0ae8bf  231  150_14\u00023916684\u00032.3979\u0001150_14\u00023940798\u00031.07056\u0001150_14\u00023892368\u00031.6259\u0001150_14\u00023914634\u00030.55962\u0001150_14...\n",
       "0001def19d7cb335  964  150_14\u00023909150\u00030.84715\u0001150_14\u00023933013\u00034.44265\u0001150_14\u00023934083\u00033.3322\u0001150_14\u00023874258\u00034.09988\u0001150_1..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_common_features_filepath = os.path.join(DIRECTORY_RAW,FILENAME_COMMON_FEATURES_TRAIN)\n",
    "df = pd.read_csv(raw_train_common_features_filepath, header=None, index_col=0, nrows=100)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have: \n",
    "\n",
    "| Column | Field                                  |\n",
    "|--------|----------------------------------------|\n",
    "| 0      | Sample-id                              |\n",
    "| 1      | Click Label                            |\n",
    "| 2      | Conversion Label                       |\n",
    "| 3      | Common Features Foreign Key            |\n",
    "| 4      | Number of features in the feature list |\n",
    "| 5      | Feature List                           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "# REMOVE-CELL\n",
    "# References and Notes\n",
    "Refer to  https://www.netquest.com/blog/en/random-sampling-stratified-sampling for sampling techniques"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4c1728eb1d2e5aa0ad9cb608f2ae480dc35c5197350e729ffcd56015e38fc7c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('deepcvr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
